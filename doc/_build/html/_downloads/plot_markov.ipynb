{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Blahng regularization in Multi-layer Perceptron\n\n\nA comparison of different values for regularization parameter 'alpha' on\nsynthetic datasets. The plot shows that different alphas yield different\ndecision functions.\n\n\nAlpha is a parameter for regularization term, aka penalty term, that combats\noverfitting by constraining the size of the weights. Increasing alpha may fix\nhigh variance (a sign of overfitting) by encouraging smaller weights, resulting\nin a decision boundary plot that appears with lesser curvatures.  Similarly,\ndecreasing alpha may fix high bias (a sign of underfitting) by encouraging\nlarger weights, potentially resulting in a more complicated decision boundary.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(__doc__)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}