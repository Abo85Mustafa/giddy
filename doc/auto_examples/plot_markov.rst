

.. _sphx_glr_auto_examples_plot_markov.py:


================================================
Blahng regularization in Multi-layer Perceptron
================================================

A comparison of different values for regularization parameter 'alpha' on
synthetic datasets. The plot shows that different alphas yield different
decision functions.


Alpha is a parameter for regularization term, aka penalty term, that combats
overfitting by constraining the size of the weights. Increasing alpha may fix
high variance (a sign of overfitting) by encouraging smaller weights, resulting
in a decision boundary plot that appears with lesser curvatures.  Similarly,
decreasing alpha may fix high bias (a sign of underfitting) by encouraging
larger weights, potentially resulting in a more complicated decision boundary.








.. code-block:: python


    print(__doc__)


**Total running time of the script:** ( 0 minutes  0.000 seconds)



.. container:: sphx-glr-footer


  .. container:: sphx-glr-download

     :download:`Download Python source code: plot_markov.py <plot_markov.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: plot_markov.ipynb <plot_markov.ipynb>`

.. rst-class:: sphx-glr-signature

    `Generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_
